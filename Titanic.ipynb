{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una solución usando árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta se explicará por partes una solución para el problema del Titanic usando árboles de decisión.\n",
    "El código original puede ser consultado en la siguiente página:\n",
    "\n",
    "https://www.kaggle.com/kushal1412/titanic/decision-tree-survivors/code\n",
    "\n",
    "El autor del código no lo explica a detalle pero es fácil de comprender con la información que se tiene del problema y usando como referencia la documentación siguiente de sklearn:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "\n",
    "\n",
    "Comenzamos importando las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego sigue importar los datos de entrenamiento y los de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consiguiendo los datos de entrenamiento y el conjunto de prueba...\n",
      "Datos de entrenamiento: 891\n",
      "Datos de prueba: 418\n"
     ]
    }
   ],
   "source": [
    "print('Consiguiendo los datos de entrenamiento y el conjunto de prueba...')\n",
    "train = pd.read_csv(\"train.csv\", dtype={\"Age\": np.float64})\n",
    "test  = pd.read_csv(\"test.csv\", dtype={\"Age\": np.float64})\n",
    "\n",
    "print 'Datos de entrenamiento:', len(train)\n",
    "\n",
    "print 'Datos de prueba:', len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendremos una función que \"armoniza\" los datos. Su trabajo es llenar campos vacíos y asignar un valor numérico a los datos que no lo sean (sexo y lugar de embarcación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def harmonize_data(titanic):\n",
    "    # Llena campos vacíos\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].mean())\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].mean())\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "    # Asigna valores numéricos a los datos para facilitar cálculos\n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 1\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "    return titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto evitaremos errores que pudiera causar un campo vacio.\n",
    "\n",
    "Usamos la función en todos los datos que usaremos para el entrenamiento y el proceso de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = harmonize_data(train)\n",
    "test_data  = harmonize_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De una vez declaramos la función que usaremos más adelante para guardar nuestrar predicciones en un archivo de Excel. En la primera columna se muestra el ID de cada pasajero y a su derecha la predicción de si sobrevivirán o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_submission(dtc, train, test, predictors, filename):\n",
    "    dtc.fit(train[predictors], train[\"Survived\"])\n",
    "    predictions = dtc.predict(test[predictors])\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con nuestros datos ya procesados, agregaremos un par de campos.\n",
    "* El campo PSA es el producto del valor de clase, sexo y edad del pasajero. Recordemos que a los campos de clase y sexo se les asignó un valor numérico.\n",
    "* El campo SP contiene el número de familiares del pasajero a bordo, dentro de los cuales se toman en cuenta hijos, esposos, hermanos y padres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"PSA\"] = train_data[\"Pclass\"]*train_data[\"Sex\"]*train_data[\"Age\"]\n",
    "train_data[\"SP\"] = train_data[\"SibSp\"]+train_data[\"Parch\"]\n",
    "test_data[\"PSA\"] = test_data[\"Pclass\"]*test_data[\"Sex\"]*test_data[\"Age\"]\n",
    "test_data[\"SP\"] = test_data[\"SibSp\"]+test_data[\"Parch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora fijaremos nuestros \"predictores\", que serán los atributos que tomaremos en cuenta de cada pasajero para calcular predicciones. Estos campos son:\n",
    "* Clase\n",
    "* Sexo\n",
    "* Edad\n",
    "* PSA\n",
    "* Cantidad que pagó por el boleto\n",
    "* Lugar de embarcación\n",
    "* SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"PSA\", \"Fare\", \"Embarked\", \"SP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En *sklearn* los árboles incluyen la función *score*, la cual regresa la precisión de los datos de prueba, dando como parámetros estos datos y las clases a las que pertenece cada uno. Usaremos esto para calcular la profundidad (llamada *max_depth* por el algoritmo) que nos dé los resultados más acertados, probando cada caso del 1 al 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.82712858926342059)\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "best_n = 0\n",
    "for n in range(1,100):\n",
    "    dtc_scr = 0.\n",
    "    dtc = DecisionTreeClassifier(max_depth=n)\n",
    "    for train, test in KFold(len(train_data), n_folds=10, shuffle=True):\n",
    "        dtc.fit(train_data[predictors].T[train].T, train_data[\"Survived\"].T[train].T)\n",
    "        dtc_scr += dtc.score(train_data[predictors].T[test].T, train_data[\"Survived\"].T[test].T)/10\n",
    "    if dtc_scr > max_score:\n",
    "        max_score = dtc_scr\n",
    "        best_n = n\n",
    "print(best_n, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro parámetro del arbol de decisión es *min_samples_split*, el cual es el mínimo número de muestras necesarias para partir un nodo. Al igual que con la profundidad, buscaremos el mejor valor para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 0.8327215980024969)\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "best_s = 0\n",
    "for s in range(1,100):\n",
    "    dtc_scr = 0.\n",
    "    dtc = DecisionTreeClassifier(min_samples_split=s)\n",
    "    for train, test in KFold(len(train_data), n_folds=10, shuffle=True):\n",
    "        dtc.fit(train_data[predictors].T[train].T, train_data[\"Survived\"].T[train].T)\n",
    "        dtc_scr += dtc.score(train_data[predictors].T[test].T, train_data[\"Survived\"].T[test].T)/10\n",
    "    if dtc_scr > max_score:\n",
    "        max_score = dtc_scr\n",
    "        best_s = s\n",
    "print(best_s, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto ya podemos crear nuestro arbol de decisión. El código original usaba como criterio *entropy* y un separador de nodos *random*. El criterio puede cambiarse a *gini* para usar la impureza de Gini en vez de ganancia de información, y como estrategia para el separador se puede cambiar a *best* para elegir la mejor separación (*random* usa la mejor separación aleatoria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = DecisionTreeClassifier(max_depth=best_n, min_samples_split=best_s, criterion='entropy', splitter='random')\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"dtcsurvivors.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer unas modificaciones al algoritmo para ver cómo cambian los resultados. Cambiaremos el criterio al *default* y el separador a *best*; o lo que es lo mismo: no asignarles valor y usarán estos por default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = DecisionTreeClassifier(max_depth=best_n, min_samples_split=best_s)\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"dtcsurvivors2.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correremos el algoritmo varias veces y veremos los resultados que nos arroja Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo original   |   Modificado\n",
      "--------------------------------------\n",
      "0.76077              |     0.7799\n",
      "0.7799               |     0.77512\n",
      "0.78947              |     0.78947\n",
      "0.78947              |     0.7799\n",
      "--------------------------------------\n",
      "0.7799025            |     0.7810975\n"
     ]
    }
   ],
   "source": [
    "Resultados = [[0.76077, 0.77990], [0.77990, 0.77512], [0.78947, 0.78947], [0.78947, 0.77990]]\n",
    "Promedio = [0,0]\n",
    "\n",
    "for i in range(0,4):\n",
    "    Promedio[0] += Resultados[i][0]/4.0\n",
    "    Promedio[1] += Resultados[i][1]/4.0\n",
    "\n",
    "    \n",
    "    \n",
    "print \"Algoritmo original   |   Modificado\"\n",
    "print \"--------------------------------------\"\n",
    "print Resultados[0][0], '             |    ', Resultados[0][1]\n",
    "print Resultados[1][0], '              |    ', Resultados[1][1]\n",
    "print Resultados[2][0], '             |    ', Resultados[2][1]\n",
    "print Resultados[3][0], '             |    ', Resultados[3][1]\n",
    "print \"--------------------------------------\"\n",
    "print Promedio[0], '           |    ', Promedio[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque son pocas pruebas, en ellas el algoritmo de árboles de búsqueda con los parámetros por default ('Modificado') en vez de los que se daba originalmente ('Algoritmo Original') arroja resultados ligeramente superiores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
